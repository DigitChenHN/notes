# 引言
你知道的（其实是“我知道的”:rofl:），pytorch中建立神经网络模型可以通过自定义一个`nn.Module`的子类来构建，并通过实例化这个类来使用该模型。  
构建一个完整的神经网络模型的类，需要首先继承类`nn.Module`，然后重定义两个方法`__init__`和`forward`。其中，`__init__`方法用于定义模型的结构，`forward`方法用于定义模型的前向传播过程，即怎么从输入计算得到输出的过程。   
```python
class MyModel(nn.Module):
    def __init__(self):
        self.conv = nn.Conv2d(in_channels=3, out_channels=20, kernel_size=3)
        self.linear = nn.Linear(500, 10)
    def forward(self, x):
        bs, c, h, w = x.shape
        x = self.conv(x)  
        x = x.reshape(bs, -1)
        x = self.linear(x)
        x = nn.functional.leaky_relu(x)     
        return x    
```
在定义模型的类的过程中，往往会使用到一些内置的类，比如`nn.Linear`。这些类其实也是继承自`nn.Module`的，本质上也是定义了如何从输入计算得到输出的过程（:laughing:好像是废话）。而对于`nn.Linear`的计算过程，我们知道，首先要定义一个特定形状的权重矩阵W和偏置b，然后和输入x进行矩阵乘法运算$Wx+b$得到输出。  
在pytorch中，通过`nn.Tensor`来表示矩阵（张量）这种数据类型，而`nn.Parameter`是`nn.Tensor`的子类，其特殊之处在于：如果在定义一个module中使用`nn.Parameter`来定义一个参数（具体而言，将`nn.Parameter`的一个实例赋值为模型的一个属性），那么这个参数会被自动加入到模型的参数列表中，调用`model.parameters()`会返回这个参数，同时`nn.Parameter(requires_grad=True)`中`requires_grad=True`默认了这个参数的梯度会被记录，从而在反向传播时会被更新。  
## 参数相关方法  
### `model.parameters()`  
返回一个生成器，生成器中的元素是`nn.Parameter`的实例，即模型参数张量。这个生成器往往用作优化器`optimizer`的参数，比如，`optimizer = torch.optim.Adam(model.parameters(), lr=0.005)`。  

### `model.named_parameters()`    
`model.named_parameters()`返回一个生成器，生成器中的元素是元组，元组中的第一个元素是参数名，第二个元素是`nn.Parameter`的实例。由于显示参数名，所以想要观察模型参数时往往可以使用该方法： 
```python 
for name, param in model.named_parameters():
    print(f'{name}: {param.numel()}')  
```
> `.numel()`方法可以用来计算张量中元素的数量。  

### `model.state_dict()`  
`model.state_dict()`返回的是一个`OrderedDict`对象（这个`OrderedDict`实现的就是一个有序字典的功能，本质上还是一个字典），这个字典的键是参数的名称（实际上就是这个神经网络类.属性.属性.属性....的名称）,而值就是这个参数的值，在pytorch中是一个张量。
```python
class MyModel(nn.Module):
    def __init__(self):
        self.conv = nn.Conv2d(in_channels=3, out_channels=20, kernel_size=3)
        self.linear = nn.Linear(500, 10)
    def forward(self, x):
        bs, c, h, w = x.shape
        x = self.conv(x)  
        x = x.reshape(bs, -1)
        x = self.linear(x)
        x = nn.functional.leaky_relu(x)     
        return x   

>>> model = MyModel()
>>> print(model.state_dict().keys())
odict_keys(['conv.weight', 'conv.bias', 'linear.weight', 'linear.bias']) 
```
比如，示例神经网络类MyModel的一个属性linear，在定义时给他赋值了`nn.Linear`这个类的一个实例，而我们知道，`nn.Linear`这个类本身是有一个属性weight的，并且这个weight属性在创建这个实例的时候，应该是赋值了一个`nn.Parameter`的实例，即一个张量，这样一来最终这个神经网络调用`state_dict()`方法得到的这个有序字典中，其中一个元素的键就是linear.weight，其值是一个`nn.Parameter`。  
此外，`state_dict()`这个方法返回的字典包含了模型的参数和缓冲区（如BatchNorm中的运行均值和方差），因为包含的参数完整，一般用来将保存和加载模型的状态。  

### `model.named_modules()`  
`model.named_modules()`返回一个生成器，生成器中的元素是元组，元组中的第一个元素是模块名，第二个元素是这个模块本身。模块是按照层级顺序生成的，具体可以看例子：  
```python 
class SimpleModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(10, 5)
        self.fc2 = nn.Linear(5, 2)

>>> model = SimpleModel()
>>> for name, module in model.named_modules():
···     print("named_modules:", name, module)    
···
named_modules:  SimpleModel(
  (fc1): Linear(in_features=10, out_features=5, bias=True)
  (fc2): Linear(in_features=5, out_features=2, bias=True)
)
named_modules: fc1 Linear(in_features=10, out_features=5, bias=True)
named_modules: fc2 Linear(in_features=5, out_features=2, bias=True)
```

> 一个对于生成器的简单理解：  
> 考虑定义一个函数，其中通过循环来计算得到想要的数据，然后使用一个列表将这些数据记录下来，最后用`return`关键字返回一整个列表；而生成器函数则是在循环的最后，不是将结果存放在列表中，而是用关键字`yield`来返回本次循环得到的结果。  
> 使用`return`得到的这个函数，被调用的时候会将结果全部计算出来，如果将其赋值给一个变量，则该变量就是一个列表。而使用`yield`得到的这个生成器函数，被调用时会得到一个生成器对象，生成器对象是可迭代的，最常用的方式就是将他作为for循环迭代的对象，这样每次循环就是生成器计算并返回一个值。在pytorch中最常见到的生成器就是`nn.data.DataLoader`。

## 模型保存和加载  
由于`model.state_dict()`导出的是参数的地址（保存参数的属性变量的完整名称）、参数本身以及缓存区的数据，因此只要构建一个结构相同的模型，就可以根据参数的地址将参数值填入到模型中，就可以得到原来一样的模型。  
- 仅保存模型参数：
```python
torch.save(model.state_dict(), 'model_param.pt')
```
- 加载模型参数：
```python 
model.load_state_dict(torch.load('model_param.pt'))
```
保存和加载模型参数最重要的是保证参数的地址相同，即`model`这个实例的属性名要与原来的模型能够对的上。  
如果对不上的话会导致无法加载参数，因此往往也可以考虑保存整个模型，包括结构和参数。  
- 保存整个模型：
```python
torch.save(model, 'model.pt')
```
- 加载整个模型：
```python
model = torch.load('model.pt')
```
这里就涉及到了.pt文件，这种文件是pytorch特有的文件格式，可以用来保存pytorch中各种类型的数据：
- 保存训练好的模型。
- 保存模型的参数（权重和偏置）。
- 保存优化器的状态。
- 保存检查点（checkpoints），用于恢复训练。
- 保存任意的 PyTorch 张量或其他对象。  

也就是说，除了保存模型、参数（张量），pt文件还能用来保存其他pytorch中各种数据类型，包括字典。  
比如保存检查点（checkpoints），checkpoints本质上是保存一个字典：    
```python 
checkpoint = {
    "net": model.state_dict(), # 保存模型参数
    "optimizer": optimizer.state_dict(),
    "epoch": 20
}
torch.save(checkpoint, 'checkpoint.pt')
```
加载：
```python 
checkpoint = torch.load('checkpoint.pt') 
model.load_state_dict(checkpoint['net'])
optimizer.load_state_dict(checkpoint['optimizer'])
epoch = checkpoint['epoch']
```
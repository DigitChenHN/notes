# 大模型微调技术
本文主要参考[文章](https://blog.csdn.net/sinat_39620217/article/details/131751780)

## SFT
SFT（supervised Fine-Tuning）是指保留原模型中除了输出层之外的所有参数从而得到一个新的模型，新模型的输出大小为目标数据集类别个数，并随机初始化该层的参数，然后在新数据集上从头训练整个模型的参数。  
比如在计算机视觉的模型中，低层网络可以学习到一些边缘特征，而中层网络可能是学习到一些物体的局部轮廓，高层网络用于抽象语义。因此高层的参数往往跟数据集的标签相关，所以在其他任务上无法复用。但是低层的网络参数是可以复用的。  

## LoRA
在大语言模型中，参数数量可以到达千亿的级别，比如Deepseek-v3（671B）的参数量为6710亿，这种规模的参数量使用传统的SFT方法进行参数微调计算量非常大，因此出现了许多高效的微调方法（Parameter Efficient Fine Tuning）。   
LoRA（Low-Rank Adaptation）是一种低秩的微调方法。LoRA的基本原理是冻结预训练好的模型权重参数，在冻结原模型参数的情况下，通过往模型中加入额外的网络层，并且只训练这些网络层的参数。即$W_0+\Delta W = W_0+AB$，并且只训练$\Delta W$。  
虽然$\Delta W$看起来规模和$W$是一样的，但是$\Delta W$的秩很小，意味着可以将其分解为两个低阶的矩阵$A$和$B$相乘，这样需要训练的参数量就从$num(\Delta W)$减少到$num(A)+num(B)$。（其中$num()$表示矩阵中元素的数量）

## P-Tuning v2
